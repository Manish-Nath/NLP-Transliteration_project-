
# Language Modelling Assignment 2

### Author: Manish Nath  
### SR Number: 22754

## Table of Contents
1. [Introduction](#introduction)
2. [Project Structure](#project-structure)
3. [Setup Instructions](#setup-instructions)
4. [Model Details](#model-details)
5. [Training and Evaluation](#training-and-evaluation)
6. [Evaluation Metrics](#evaluation-metrics)
7. [Files in the Directory](#files-in-the-directory)

## Introduction
This project is part of an assignment to model Indian names using character-level language models. The task involves transliterating Indian names into Hindi using various language modeling techniques such as RNN-based Encoder-Decoder models.

## Project Structure
```bash
Manish_Nath_22754_assignment2/
│
├── Manish_Nath_22754_assignment2.py  # Main script with the code
├── README.md                         # This README file
├── rnn/
│   ├── model.pt                      # Trained RNN model
│   ├── vocab.pt                      # Vocabulary file
│   └── loss.json                     # Loss history for training
├── src_tokenizer/                    # Tokenizer files for source (Indian names)
│   └── tokenizer.pkl
├── tgt_tokenizer/                    # Tokenizer files for target (Hindi names)
│   └── tokenizer.pkl
└── outputs.csv                       # Final model predictions
```

## Setup Instructions

### Environment Setup
Make sure you are working in a Python 3 environment. If not, follow these steps:

1. **Create a Virtual Environment**:
   ```bash
   python3 -m venv assignment2_env
   ```

2. **Activate the Virtual Environment**:
   ```bash
   source assignment2_env/bin/activate
   ```

3. **Install Required Packages**:
   ```bash
   pip install torch torchvision torchaudio torchtext tqdm nltk matplotlib numpy pandas
   ```

### Run the Code
To run the project:

1. Make sure the required training and validation data is available by running the data download commands.
2. Execute the main script `Manish_Nath_22754_assignment2.py`.
   ```bash
   python Manish_Nath_22754_assignment2.py
   ```

The model will automatically resume from the last checkpoint if the training was interrupted. You can also find the output translations generated by the model in `outputs.csv`.

## Model Details

The project implements various models for language modeling. The primary focus is on **RNN-based Encoder-Decoder** networks. The models take an Indian name as input and predict the transliterated Hindi name.

### Tokenizer
The custom tokenizer is implemented in the `Tokenizer` class. It supports:
- Special tokens (`<pad>`, `<unk>`, `<sos>`, `<eos>`)
- Encoding and decoding of strings
- Padding and batch processing

### RNN Encoder-Decoder Model
The RNN model includes:
- **GRU-based Encoder-Decoder**: The encoder processes the input sequence (Indian names), and the decoder generates the target sequence (Hindi names).
- **Embedding Layer**: To map characters into a continuous vector space.
- **Dropout**: Applied for regularization.
- **Linear Layer**: Final layer to map hidden states to the vocabulary.

### Optimizer and Loss
- **Optimizer**: Adam optimizer is used for efficient gradient-based optimization.
- **Loss Function**: Negative Log-Likelihood Loss (NLLLoss) is used to optimize the model.

## Training and Evaluation

### Training
To train the model:
1. Load the training and validation datasets.
2. Train using the `Trainer` class, which handles data loading, loss computation, and checkpointing.

The training process involves:
- Forward propagation through the RNN Encoder-Decoder model.
- Backpropagation to minimize the loss.
- Checkpoints are saved periodically.

### Evaluation
Evaluation is done using the following metrics:
- **Accuracy**: Measures how many translations match exactly.
- **Character Error Rate (CER)**: Measures the rate of character-level errors.
- **Token Error Rate (TER)**: Measures the rate of token-level errors.
- **BLEU Score**: Measures n-gram overlap between the generated translations and the reference translations.

## Evaluation Metrics

- **Accuracy**: Measures how often the model’s output matches the exact expected output.
- **CER (Character Error Rate)**: Measures the number of character edits (insertions, deletions, substitutions) required to convert the model output into the target.
- **TER (Token Error Rate)**: Similar to CER but computed at the token level.
- **BLEU**: The Bilingual Evaluation Understudy Score is a metric based on n-gram overlap between model output and ground truth.

## Files in the Directory

- `Manish_Nath_22754_assignment2.py`: The main code file for the assignment.
- `src_tokenizer/tokenizer.pkl`: Tokenizer for the source (Indian names).
- `tgt_tokenizer/tokenizer.pkl`: Tokenizer for the target (Hindi names).
- `rnn/model.pt`: The trained RNN model.
- `rnn/loss.json`: JSON file storing the training loss history.
- `outputs.csv`: The predictions made by the trained model.

---

This README provides an overview of the project, the models used, and how to set up the environment and run the code. Let me know if you need any additional sections or clarifications!
